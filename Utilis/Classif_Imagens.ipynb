{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ri9zu_gP0F2NbtmHLpY2JULq1IL6z4G7","authorship_tag":"ABX9TyOikx5y/ShDKPyN3/9L6Rjt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install patchify"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3EFL6VKelzUd","executionInfo":{"status":"ok","timestamp":1681741278267,"user_tz":180,"elapsed":6300,"user":{"displayName":"gabriel monaco ribeiro da silva","userId":"10759892669823803157"}},"outputId":"801951c5-ada0-4915-8c94-46a72755f38a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting patchify\n","  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from patchify) (1.22.4)\n","Installing collected packages: patchify\n","Successfully installed patchify-0.2.3\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from keras.utils import normalize\n","from matplotlib import pyplot as plt"],"metadata":{"id":"0zgI3n6ThPib","executionInfo":{"status":"ok","timestamp":1681749811813,"user_tz":180,"elapsed":3,"user":{"displayName":"gabriel monaco ribeiro da silva","userId":"10759892669823803157"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["patch_size=256\n"],"metadata":{"id":"NSMTE54ThPfT","executionInfo":{"status":"ok","timestamp":1681749058911,"user_tz":180,"elapsed":2,"user":{"displayName":"gabriel monaco ribeiro da silva","userId":"10759892669823803157"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["\n","from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers import Activation, MaxPool2D, Concatenate\n","\n","\n","def conv_block(input, num_filters): # Duas convoluções \n","    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n","    x = BatchNormalization()(x)   #Not in the original network. \n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)  #Not in the original network\n","    x = Activation(\"relu\")(x)   # ReLu como função de ativação\n","\n","    return x\n","\n","\n","#Encoder block: Conv block followed by maxpooling\n","def encoder_block(input, num_filters):\n","    x = conv_block(input, num_filters) # gerar features\n","    p = MaxPool2D((2, 2))(x)    # Reduz as imagens a aprtir de um kernel 2x2\n","    return x, p   \n","\n","#Decoder block\n","#skip features gets input from encoder for concatenation\n","def decoder_block(input, skip_features, num_filters):\n","    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n","    x = Concatenate()([x, skip_features])   # utiliza a posição dos pixels do encoder\n","    x = conv_block(x, num_filters)\n","    return x\n","\n","#Build Unet using the blocks\n","def build_unet(input_shape, n_classes):\n","    inputs = Input(input_shape)\n","\n","    s1, p1 = encoder_block(inputs, 64)\n","    s2, p2 = encoder_block(p1, 128)\n","    s3, p3 = encoder_block(p2, 256)\n","    s4, p4 = encoder_block(p3, 512)\n","\n","    b1 = conv_block(p4, 1024) #Bridge\n","\n","    d1 = decoder_block(b1, s4, 512)\n","    d2 = decoder_block(d1, s3, 256)\n","    d3 = decoder_block(d2, s2, 128)\n","    d4 = decoder_block(d3, s1, 64)\n","\n","    #Change the activation based on n_classes\n","    if n_classes == 1:  #Binary\n","      activation = 'sigmoid'\n","    else:               # mulsti-class classification\n","      activation = 'softmax'\n","\n","    # Output convolution\n","    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)  \n","    print(activation)\n","\n","    model = Model(inputs, outputs, name=\"U-Net\")\n","    return model"],"metadata":{"id":"9ZrXcPwXhPac","executionInfo":{"status":"ok","timestamp":1681749487484,"user_tz":180,"elapsed":497,"user":{"displayName":"gabriel monaco ribeiro da silva","userId":"10759892669823803157"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def get_model():\n","    return build_unet(input_shape, n_classes)\n","\n","input_shape = (patch_size, patch_size, 1)\n","n_classes = 6"],"metadata":{"id":"yj-e9bkpDk-K","executionInfo":{"status":"ok","timestamp":1681749672284,"user_tz":180,"elapsed":4,"user":{"displayName":"gabriel monaco ribeiro da silva","userId":"10759892669823803157"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def prediction(model, image, patch_size):\n","    segm_img = np.zeros(image.shape[:2])  #Array with zeros to be filled with segmented values\n","    patch_num=1\n","    for i in range(0, image.shape[0], 256):   #Steps of 256\n","        for j in range(0, image.shape[1], 256):  #Steps of 256\n","            #print(i, j)\n","            single_patch = image[i:i+patch_size, j:j+patch_size]\n","            single_patch_norm = np.expand_dims(normalize(np.array(single_patch), axis=1),2)\n","            single_patch_shape = single_patch_norm.shape[:2]\n","            single_patch_input = np.expand_dims(single_patch_norm, 0)\n","            single_patch_prediction = (model.predict(single_patch_input)[0,:,:,0] > 0.5).astype(np.uint8)\n","            segm_img[i:i+single_patch_shape[0], j:j+single_patch_shape[1]] += cv2.resize(single_patch_prediction, single_patch_shape[::-1])\n","          \n","            print(\"Finished processing patch number \", patch_num, \" at position \", i,j)\n","            patch_num+=1\n","    return segm_img"],"metadata":{"id":"G9KnBeI_Dk7a","executionInfo":{"status":"ok","timestamp":1681749687604,"user_tz":180,"elapsed":283,"user":{"displayName":"gabriel monaco ribeiro da silva","userId":"10759892669823803157"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["##########\n","#Load model and predict\n","model = get_model()\n","#model.load_weights('mitochondria_gpu_tf1.4.hdf5')\n","model.load_weights('/content/drive/MyDrive/MEV - metamaficas/Projeto_Segmentação_Rocha_Máfica/Modelos/GIMP_348img_b12_e100.hdf5')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGXmalxLDk2X","executionInfo":{"status":"ok","timestamp":1681749693538,"user_tz":180,"elapsed":3581,"user":{"displayName":"gabriel monaco ribeiro da silva","userId":"10759892669823803157"}},"outputId":"5ad290e0-a137-4cc4-e3fd-27a81ec05bbb"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["softmax\n"]}]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/MEV - metamaficas/Classif_AT-Z-2'\n","\n","\n","for image in os.listdir(path):\n","    #Large image\n","    large_image = cv2.imread(path+image, 0)\n","    segmented_image = prediction(model, large_image, patch_size)\n","    plt.hist(segmented_image.flatten())  #Threshold everything above 0\n","\n","    plt.imsave(f'/content/drive/MyDrive/MEV - metamaficas/Masks_AT-Z-2/{image}.tif', segmented_image, cmap='gray')\n","\n","    plt.figure(figsize=(8, 8))\n","    plt.subplot(221)\n","    plt.title('Large Image')\n","    plt.imshow(large_image, cmap='gray')\n","    plt.subplot(222)\n","    plt.title('Prediction of large Image')\n","    plt.imshow(segmented_image, cmap='gray')\n","    plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"1BZ_n8BjDkzj","executionInfo":{"status":"error","timestamp":1681750161770,"user_tz":180,"elapsed":350,"user":{"displayName":"gabriel monaco ribeiro da silva","userId":"10759892669823803157"}},"outputId":"eb8b268d-0ab4-47a9-c664-36f42bb94476"},"execution_count":40,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-482afcae5576>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Large image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlarge_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msegmented_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlarge_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmented_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Threshold everything above 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-08ad4db56c4b>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(model, image, patch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msegm_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Array with zeros to be filled with segmented values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpatch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m#Steps of 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#Steps of 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}]}]}